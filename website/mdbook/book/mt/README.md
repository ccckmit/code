# 前言

Seq2seq 的《深度學習模型》，是 google 機器翻譯突飛猛進的關鍵，主要是用兩個 RNN 串在一起，一個編碼，一個解碼。
現在好像沒有《機器翻譯》的書寫這個，而網路上的資料通常只有《英法翻譯》，沒有《英中翻譯》的範例。
想了想之後，發現如果用《人造漢語》翻譯《人造英語》當範例，應該可以把整個方法闡述得很清楚....
方法是從《語言自動生成》開始下手，然後把《生成的語言》拿過來學習。
這種方是由於標準答案已經知道了，所以要驗證特別容易！
既然這樣，就來寫本《人造語言和機器翻譯》電子書好了，趁機把 seq2seq 的技術搞清楚並實作一遍 .....

* <https://www.facebook.com/ccckmit/posts/10155171979306893>